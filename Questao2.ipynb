{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spttleonardo/CNN-application/blob/main/Questao2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3bXaOlBdK5U"
      },
      "source": [
        "**Alunos:** Leonardo Schmitt e Bruno Yuri\n",
        "\n",
        "**Atividade 2**- Necessário criar um classificador de imagens utilizando redes neurais. Deve-se  definir e treinar uma rede neural convolucional que seja capaz de indetificar um conjunto de imagens e destinguir se a mesma trata-se  de um gato ou uma cobra.\n",
        "\n",
        "- Dataset utilizado: Autoria (Disponivel no Drive)\n",
        "\n",
        "Deve-se obter uma acurácia > 90% em um dataset de teste (não utilizado para treinamento e validação)\n",
        "Além disso o trabalho deve Apresentar a matriz de confusão paraanálise dos acertos e erros em cada classe\n",
        "individualmente.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oJzuvbpP8Ea"
      },
      "source": [
        "**1-** Para fazer o download do arquivo disponibilizado no drive, deve-se usar um programar chamado gdown que precisa ser instalado no ambiente. No colab, as instruções precedidas por ! são executadas como comandos do sistema operacional (no caso do colab é Linux)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tb8-d2rodHtw",
        "outputId": "3dd93ecb-a97c-4d34-afe7-958018de1976"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.17.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.1.31)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install gdown"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTnDOjkXQC6p"
      },
      "source": [
        "**2**- Uma vez instalado o gdown, deve-se usar ele para fazer downloado do arquivo dataset_pequeno.zip de um compartilhamento público (compartilhamento acessível apenas com o link) do GoogleDrive.\n",
        "\n",
        "Para obter o arquivo com o gdown, é necessário colocar o arquivo no GoogleDrive, compartilhar ele com link e extrair do link apenas o id do compartilhamento. Por exemplo, para o compartilhamento da URL abaixo:\n",
        "\n",
        "https://drive.google.com/drive/folders/1uYBF5a4IqnmmVIJr-UsGYmUs0tKymOAY?usp=sharing\n",
        "\n",
        "o id do compartilhamento é: 1uYBF5a4IqnmmVIJr-UsGYmUs0tKymOAY\n",
        "\n",
        "então basta substituir na URL abaixo que será usada pelo gdown o texto id_do_compartilhamento pelo id obtido:\n",
        "\n",
        "gdown https://drive.google.com/uc?id=id_do_compartilhamento\n",
        "\n",
        "Abaixo o uso do gdown para este arquivo (dataset_pequeno.zip) com alguns comandos adicionais comentados no texto. Caso julgue interessante, separe cada comando em uma caixa para executá-lo em separado e ver o resultado que ele produz:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bc5Sj3jQdrfv",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#Remover o dataset_pequeno.zip caso já exista\n",
        "!rm -rfv dataset_pequeno/\n",
        "\n",
        "#Remover o dirtório gerado ao descompactar o exemplo.zip caso já existe\n",
        "!rm -rfv dataset_pequeno/\n",
        "\n",
        "#Baixar o arquivo do GoogleDrive usando o gdown\n",
        "#https://drive.google.com/file/d/139g4a_E9rsZmBUGE82Sj0bIhOQxkEuAM/view?usp=sharing-  dataset com menos exemplos\n",
        "!gdown  https://drive.google.com/uc?id=139g4a_E9rsZmBUGE82Sj0bIhOQxkEuAM\n",
        "\n",
        "#Descompactar o arquivo exemplo.zip\n",
        "!unzip dataset_pequeno.zip\n",
        "\n",
        "#Lista arquivos e diretorios\n",
        "!ls -ltr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJ_4ffl6glw3"
      },
      "source": [
        "3 - Lendo os arquivos de entrada usando o ImageDataGenerator.\n",
        "\n",
        "A classe ImageDataGenerator que é parte da API do Keras é um componente de grande utilidade para carregar e fazer pré-processamento das imagens para uma rede neural programada com o Keras.\n",
        "\n",
        "Além da função de ler os arquivos contendo as imagens com base em uma organização de diretórios, ele possuí outras funcionalidades de pré-processamento, como redimensionamento, rotação, zoom, resampling, etc. Para mais detalhes visite: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator.\n",
        "\n",
        "Além do componente ImageDataGenerator, existem outros componentes e métodos para ler os dados de imagens e transformá-las em matrizes no formato necessário para usá-las em uma rede CNN. Um exemplo de outro componente é o [tf.keras.preprocessing.image_dataset_from_directory](https://keras.io/api/preprocessing/image/) entre outros."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yz9veOTRed-w",
        "outputId": "1d54b271-8e64-4da6-9fe9-f6f07a1d5c12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 600 images belonging to 2 classes.\n",
            "Found 240 images belonging to 2 classes.\n",
            "Found 360 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Definindo o tamanho (tam x tam) que sera usado para as imagens na CNN\n",
        "tam = 100\n",
        "\n",
        "gerador_treinamento = ImageDataGenerator(rescale = 1./255,\n",
        "                                         rotation_range=7,\n",
        "                                         horizontal_flip=True,\n",
        "                                         shear_range=0.2,\n",
        "                                         height_shift_range=0.07,\n",
        "                                         zoom_range=0.2)\n",
        "\n",
        "# Usando o objeto gerador_treinamento criado, para carregar os dados de treino do dataset\n",
        "base_treinamento = gerador_treinamento.flow_from_directory('dataset_pequeno/dataset/training_set',\n",
        "                                                           target_size=(tam,tam),\n",
        "                                                           batch_size=1000,\n",
        "                                                           class_mode='binary')\n",
        "\n",
        "# Normalizacao dos valores\n",
        "gerador_teste = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Realizando o carregamento das imagens de validação\n",
        "base_validacao = gerador_teste.flow_from_directory('dataset_pequeno/dataset/valid_set',\n",
        "                                                    target_size=(tam,tam),\n",
        "                                                    batch_size=1000,\n",
        "                                                    class_mode='binary')\n",
        "\n",
        "# Fazendo a carregamento  das imagens de teste\n",
        "base_teste = gerador_teste.flow_from_directory('dataset_pequeno/dataset/test_set',\n",
        "                                                target_size=(tam,tam),\n",
        "                                                batch_size=1000,\n",
        "                                                class_mode='binary')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcCdFocDi8kR"
      },
      "source": [
        "**4-** Importando módulos e definindo a rede neural convolucional.\n",
        "\n",
        "Para definir a rede neural convolucional e realizar a comparação das métricas graficamente, primeiramente deve-se importar os módulos necessários."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "from tensorflow import keras\n",
        "from matplotlib import pyplot\n",
        "from keras import optimizers\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n"
      ],
      "metadata": {
        "id": "DBpTQV4JZTAv"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definindo a rede neural utilizando a função *Sequencial()* do keras.\n",
        "\n",
        "Vale notar que utiliza-se o dropout de 25% para que nao ocorra overfitting.\n"
      ],
      "metadata": {
        "id": "9JrCY5xjaDYy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "9oc5zfHKi7FR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "outputId": "5813c088-81c1-41a3-f106-e74b87c0bd58"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m98\u001b[0m, \u001b[38;5;34m98\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m49\u001b[0m, \u001b[38;5;34m49\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m47\u001b[0m, \u001b[38;5;34m47\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m33856\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m33856\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │         \u001b[38;5;34m270,856\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m9\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">47</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">47</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33856</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33856</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">270,856</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m290,257\u001b[0m (1.11 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">290,257</span> (1.11 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m290,257\u001b[0m (1.11 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">290,257</span> (1.11 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(tam,tam,3)),\n",
        "        keras.layers.Conv2D(32, kernel_size=(3,3), activation=\"relu\"),\n",
        "        keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "        keras.layers.Conv2D(64, kernel_size=(3,3), activation=\"relu\"),\n",
        "        keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "        keras.layers.Flatten(),\n",
        "        keras.layers.Dropout(0.25),\n",
        "        keras.layers.Dense(8, activation=\"relu\"),\n",
        "        keras.layers.Dense(1, activation=\"sigmoid\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5-** Definindo parâmetros para o treinamento da CNN.\n",
        "\n",
        "O valor de epoca deve ser deixar em 150, para que o mesmo consiga atingir um valor aceital de acuracia tanto para treinamento como para teste. Além disso, a taxa de aprendizado foi ajustada para 0.03 para que melhore o resultados obtidos pelada rede neural.\n",
        "\n",
        "Destaca-se ainda que o batch_size tem como valor 8, para melhor desempenho da rede neural."
      ],
      "metadata": {
        "id": "ypf861OxazK1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vv-nNtckw33"
      },
      "outputs": [],
      "source": [
        "epochs = 150\n",
        "optimizer_exp = keras.optimizers.Adam(learning_rate=0.03)\n",
        "#SGD = keras.optimizers.SGD(learning_rate=0.01, momentum=0.0)\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer_exp, metrics=[\"accuracy\"])\n",
        "\n",
        "hist = model.fit(base_treinamento,\n",
        "                           validation_data=base_validacao,\n",
        "                           epochs=epochs,batch_size=8)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6-** Plotagem do gráficos para realizar a comparação entre a acurácia e loss do dados de treinamento e validação"
      ],
      "metadata": {
        "id": "GlYNt2y7bs6y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fl0FGyiAsM-z"
      },
      "outputs": [],
      "source": [
        "print(hist.history.keys())\n",
        "\n",
        "plt.plot(hist.history['accuracy'])\n",
        "plt.plot(hist.history['val_accuracy'])\n",
        "plt.title('model_accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(['train','valid'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('model_loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['train', 'legend'], loc='upper left')\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7-** Seção de codigo para valiar o desempenho da CNN com os dados de teste"
      ],
      "metadata": {
        "id": "KfZdGzm2b5tb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XTLWysb3tQiK"
      },
      "outputs": [],
      "source": [
        "score = model.evaluate(base_teste, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4BFwMrXJcZ4X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8-** Realização de previsões, plotagem da matriz de confusão e avaliação da acurácia.\n",
        "\n",
        "Nesta seção, busca-se demonstrar como a CNN se comporta ao realizar previsões e como validar os dados previstos por meio da matriz de confusão e da acurácia. Essas etapas são cruciais para avaliar o desempenho do modelo em dados de teste não vistos."
      ],
      "metadata": {
        "id": "RqkgFuJOc5xH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hUlFD6Xvtb1R"
      },
      "outputs": [],
      "source": [
        "images,labels=next(base_teste)\n",
        "print(images.shape)\n",
        "print(labels.shape)\n",
        "\n",
        "preditcions = (model.predict(base_teste, verbose=0)>0.5).astype(int)\n",
        "\n",
        "print('Matriz de confusão')\n",
        "print(confusion_matrix(labels, preditcions))\n",
        "\n",
        "print('Accuracy: %f' %(accuracy_score(labels, preditcions)))\n",
        "\n",
        "plt.figure(figsize=(20, 20))\n",
        "for i in range(25):\n",
        "    ax = plt.subplot(5, 5, i + 1)\n",
        "    plt.imshow(images[i])\n",
        "    plt.title(list(base_teste.class_indices.keys())[labels[i].astype(int)] + \"->\" + list(base_teste.class_indices.keys())[preditcions[i,0].astype(int)])\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "print(np.column_stack((labels, preditcions)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Destarte, conclui-se que o objetivo pode ser alcançado pera as configurações da rede neural presente. Além disso, a forma como foi definido os parâmetros são o suficiente para poder alcançar um acurácia acima de 90%.\n",
        "\n",
        "Entretanto, devido ao ruido presente nas imagens, como também do mal condicionamento das imagens, pode acontecer de a acurácia ficar abaixo dos 90%."
      ],
      "metadata": {
        "id": "aAbU56BAWH3_"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPaMI9L5A2/M8VJw1lRRp6m",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}